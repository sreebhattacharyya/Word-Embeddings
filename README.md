# Word-Embeddings
Simple procedures followed to understand how vector space models work
I have tried to explore the following after learning from my NLP course assignment:
1. Predicting analogies between words (by predicting countries when capitals are given)
2. Using PCA to reduce dimensionality of the word embeddings and visualize words
3. Explore the working of vector space models
